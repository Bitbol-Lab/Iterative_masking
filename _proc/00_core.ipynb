{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DC\n",
       "\n",
       ">      DC (x)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DC\n",
       "\n",
       ">      DC (x)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### IM_MSA_Transformer\n",
       "\n",
       ">      IM_MSA_Transformer (iterations=None, p_mask=None, filename=None,\n",
       ">                          num=None, filepath=None, DEVICE=device(type='cpu'),\n",
       ">                          pretrained_model_path=None)\n",
       "\n",
       "Class that implement the Iterative masking algorithm"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### IM_MSA_Transformer\n",
       "\n",
       ">      IM_MSA_Transformer (iterations=None, p_mask=None, filename=None,\n",
       ">                          num=None, filepath=None, DEVICE=device(type='cpu'),\n",
       ">                          pretrained_model_path=None)\n",
       "\n",
       "Class that implement the Iterative masking algorithm"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(IM_MSA_Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### IM_MSA_Transformer.Batch_MSA\n",
       "\n",
       ">      IM_MSA_Transformer.Batch_MSA (use_pdf=False, simplified=False,\n",
       ">                                    repetitions=2, sample_all=False, T=1,\n",
       ">                                    phylo=False)\n",
       "\n",
       "Generate a full MSA by calling with different input MSAs the iterative MSA generator defined\n",
       "in: `self.NEW_MSA`.\n",
       "\n",
       "---> Use this function with `simplified`=False only if you need tokens in cuda ! (i.e. if you want to compute embed\n",
       "     or contacs), otherwise use `simplified`=True\n",
       "\n",
       "The variable `self.iterations` must be a numpy array which specifies when (at which iterations)\n",
       "the tokens must be saved. The last element of the array gives the maximum number of iterations that should be done.\n",
       "\n",
       "`repetitions`:      the number of times self.NEW_MSA() is repeated with a different input MSA.\n",
       "\n",
       "`use_pdf`:    if it's True the function sample the token from the logits pdf \n",
       "            instead of getting the argmax (greedy sampling).\n",
       "\n",
       "`sample_all`: if True all the new tokens are obtained from the logits (both\n",
       "            the masked and the non masked), if False the non masked tokens\n",
       "            are left untouched and only the masked ones are changed.\n",
       "\n",
       "`T`:          Temperature of sampling from the pdf of output logits.\n",
       "\n",
       "`phylo`:            if True the start sequences are sampled from phylogeny weights instead of randomly."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### IM_MSA_Transformer.Batch_MSA\n",
       "\n",
       ">      IM_MSA_Transformer.Batch_MSA (use_pdf=False, simplified=False,\n",
       ">                                    repetitions=2, sample_all=False, T=1,\n",
       ">                                    phylo=False)\n",
       "\n",
       "Generate a full MSA by calling with different input MSAs the iterative MSA generator defined\n",
       "in: `self.NEW_MSA`.\n",
       "\n",
       "---> Use this function with `simplified`=False only if you need tokens in cuda ! (i.e. if you want to compute embed\n",
       "     or contacs), otherwise use `simplified`=True\n",
       "\n",
       "The variable `self.iterations` must be a numpy array which specifies when (at which iterations)\n",
       "the tokens must be saved. The last element of the array gives the maximum number of iterations that should be done.\n",
       "\n",
       "`repetitions`:      the number of times self.NEW_MSA() is repeated with a different input MSA.\n",
       "\n",
       "`use_pdf`:    if it's True the function sample the token from the logits pdf \n",
       "            instead of getting the argmax (greedy sampling).\n",
       "\n",
       "`sample_all`: if True all the new tokens are obtained from the logits (both\n",
       "            the masked and the non masked), if False the non masked tokens\n",
       "            are left untouched and only the masked ones are changed.\n",
       "\n",
       "`T`:          Temperature of sampling from the pdf of output logits.\n",
       "\n",
       "`phylo`:            if True the start sequences are sampled from phylogeny weights instead of randomly."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(IM_MSA_Transformer.Batch_MSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### IM_MSA_Transformer.Context_MSA\n",
       "\n",
       ">      IM_MSA_Transformer.Context_MSA (depth=None, ancestor=None, context=None,\n",
       ">                                      use_pdf=False, simplified=False,\n",
       ">                                      sample_all=False, print_all=True, T=1)\n",
       "\n",
       "Generates a new MSA with context-generation by iterating the masking on the original ancestor sequence\n",
       "using: `self.generate_MSA_context`. It masks `ancestor` (original sequence) and uses the sequences in `context` as context MSA.\n",
       "\n",
       "---> Use this function with `simplified`=False only if you need tokens in cuda ! (i.e. if you want to compute embed\n",
       "     or contacs), otherwise use `simplified`=True\n",
       "\n",
       "The variable `self.iterations` must be a numpy array which specifies when (at which iterations)\n",
       "the tokens must be saved. The last element of the array gives the maximum number of iterations that should be done.\n",
       "If `print_all`=True then it saves the generated sequences at each iteration.\n",
       "\n",
       "`ancestor`:     input sequence to be masked iteratively.\n",
       "\n",
       "`context`:      context MSA (not masked).\n",
       "\n",
       "`use_pdf`:      if it's True the function sample the token from the logits pdf \n",
       "                instead of getting the argmax (greedy sampling).\n",
       "\n",
       "`sample_all`:   if True all the new tokens are obtained from the logits (both\n",
       "                the masked and the non masked), if False the non masked tokens\n",
       "                are left untouched and only the masked ones are changed.\n",
       "\n",
       "`T`:            Temperature of sampling from the pdf of output logits.\n",
       "\n",
       "`depth`:        number of generated sequences, if None the depth is the number of ancestor sequences."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### IM_MSA_Transformer.Context_MSA\n",
       "\n",
       ">      IM_MSA_Transformer.Context_MSA (depth=None, ancestor=None, context=None,\n",
       ">                                      use_pdf=False, simplified=False,\n",
       ">                                      sample_all=False, print_all=True, T=1)\n",
       "\n",
       "Generates a new MSA with context-generation by iterating the masking on the original ancestor sequence\n",
       "using: `self.generate_MSA_context`. It masks `ancestor` (original sequence) and uses the sequences in `context` as context MSA.\n",
       "\n",
       "---> Use this function with `simplified`=False only if you need tokens in cuda ! (i.e. if you want to compute embed\n",
       "     or contacs), otherwise use `simplified`=True\n",
       "\n",
       "The variable `self.iterations` must be a numpy array which specifies when (at which iterations)\n",
       "the tokens must be saved. The last element of the array gives the maximum number of iterations that should be done.\n",
       "If `print_all`=True then it saves the generated sequences at each iteration.\n",
       "\n",
       "`ancestor`:     input sequence to be masked iteratively.\n",
       "\n",
       "`context`:      context MSA (not masked).\n",
       "\n",
       "`use_pdf`:      if it's True the function sample the token from the logits pdf \n",
       "                instead of getting the argmax (greedy sampling).\n",
       "\n",
       "`sample_all`:   if True all the new tokens are obtained from the logits (both\n",
       "                the masked and the non masked), if False the non masked tokens\n",
       "                are left untouched and only the masked ones are changed.\n",
       "\n",
       "`T`:            Temperature of sampling from the pdf of output logits.\n",
       "\n",
       "`depth`:        number of generated sequences, if None the depth is the number of ancestor sequences."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(IM_MSA_Transformer.Context_MSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### gen_MSAs\n",
       "\n",
       ">      gen_MSAs (filepath:str<Pathoftheinputdirectory>,\n",
       ">                filename:str<Nameoftheinputfile(s)>,\n",
       ">                new_dir:str<Nameoftheoutputdirectory>,\n",
       ">                pdf:bool_arg<ShouldIsampletokensfromthepdf?(bool)>, T:float<Whi\n",
       ">                chisthesamplingTemperaturefromthepdf?(onlywhen`pdf`isTrue)>, sa\n",
       ">                mple_all:bool_arg<ShouldIsamplealltokensorjustthemaskedones?(Tr\n",
       ">                ue=samplealltokens)>,\n",
       ">                Iters:int<Numberoftotaliterationstogeneratethenewtokens>,\n",
       ">                pmask:float<Maskingprobability>,\n",
       ">                num:int<SizeofthebatchesMSAswhichtheMSA-\n",
       ">                Transformerreceivesasinput>,\n",
       ">                depth:int<Numberofbatches(ofsizenum)thatyouwanttogenerate>, gen\n",
       ">                erate:str<HowshouldIgeneratesequences?False(=Batchgeneration)or\n",
       ">                Linearwithcontext(=linear-ran/linear-tot-ran),`-ran`meansthatth\n",
       ">                econtextMSAissampledrandomly(once)while`-tot-\n",
       ">                ran`meansthatitissampledrandomlyeachtime.>, print_all:bool_arg<\n",
       ">                ShouldIprinttheMSAaftereachiteration?(bool)>, range_vals:int<Fi\n",
       ">                rstandlastindexofthesequencesthatyouwanttouseasancestors>, phyl\n",
       ">                o_w:bool_arg<ShouldIsamplethestartingsequencesfromthephylogenyw\n",
       ">                eights?(bool)>)\n",
       "\n",
       "Generate a new MSA either with Batch generation of Context generation. It shuffles the initial MSA and uses different slices as batch MSAs"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### gen_MSAs\n",
       "\n",
       ">      gen_MSAs (filepath:str<Pathoftheinputdirectory>,\n",
       ">                filename:str<Nameoftheinputfile(s)>,\n",
       ">                new_dir:str<Nameoftheoutputdirectory>,\n",
       ">                pdf:bool_arg<ShouldIsampletokensfromthepdf?(bool)>, T:float<Whi\n",
       ">                chisthesamplingTemperaturefromthepdf?(onlywhen`pdf`isTrue)>, sa\n",
       ">                mple_all:bool_arg<ShouldIsamplealltokensorjustthemaskedones?(Tr\n",
       ">                ue=samplealltokens)>,\n",
       ">                Iters:int<Numberoftotaliterationstogeneratethenewtokens>,\n",
       ">                pmask:float<Maskingprobability>,\n",
       ">                num:int<SizeofthebatchesMSAswhichtheMSA-\n",
       ">                Transformerreceivesasinput>,\n",
       ">                depth:int<Numberofbatches(ofsizenum)thatyouwanttogenerate>, gen\n",
       ">                erate:str<HowshouldIgeneratesequences?False(=Batchgeneration)or\n",
       ">                Linearwithcontext(=linear-ran/linear-tot-ran),`-ran`meansthatth\n",
       ">                econtextMSAissampledrandomly(once)while`-tot-\n",
       ">                ran`meansthatitissampledrandomlyeachtime.>, print_all:bool_arg<\n",
       ">                ShouldIprinttheMSAaftereachiteration?(bool)>, range_vals:int<Fi\n",
       ">                rstandlastindexofthesequencesthatyouwanttouseasancestors>, phyl\n",
       ">                o_w:bool_arg<ShouldIsamplethestartingsequencesfromthephylogenyw\n",
       ">                eights?(bool)>)\n",
       "\n",
       "Generate a new MSA either with Batch generation of Context generation. It shuffles the initial MSA and uses different slices as batch MSAs"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(gen_MSAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build library"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
